{"cells":[{"cell_type":"markdown","metadata":{"id":"gqJBNYxGcB5B"},"source":["# Getting started with Task 1"]},{"cell_type":"markdown","metadata":{"id":"2LY5yi11cB5B"},"source":["Instructions:\n","- Download the dataset from the [ECG Heartbeat Categorization Dataset](https://www.kaggle.com/datasets/shayanfazeli/heartbeat)\n","- Unzip the `archive.zip` file\n","- Rename the folder `archive` as `ecg_dataset` and place it in the root of the git repository"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"ckl6TJTkdL8P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1689025240122,"user_tz":420,"elapsed":1297,"user":{"displayName":"Shaan Pakala","userId":"10109696484997983092"}},"outputId":"ecaa8011-dfb2-445f-824a-e52acdb043a1"},"execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"markdown","metadata":{"id":"f5QZ07VUcB5C"},"source":["References:\n","- [ECG Heartbeat Classification: A Deep Transferable Representation](https://arxiv.org/pdf/1805.00794.pdf)"]},{"cell_type":"markdown","metadata":{"id":"IfG9RNqwcB5C"},"source":["## Load dependencies"]},{"cell_type":"code","execution_count":170,"metadata":{"id":"mU-_gP8zcB5D","executionInfo":{"status":"ok","timestamp":1689025240123,"user_tz":420,"elapsed":4,"user":{"displayName":"Shaan Pakala","userId":"10109696484997983092"}}},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt"]},{"cell_type":"code","source":["drive_path = '/content/drive/MyDrive/cardiac_challenge_team6'"],"metadata":{"id":"OiJSt0QWjFnr","executionInfo":{"status":"ok","timestamp":1689025240123,"user_tz":420,"elapsed":3,"user":{"displayName":"Shaan Pakala","userId":"10109696484997983092"}}},"execution_count":171,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q1_zMBh3cB5D"},"source":["## The PTB Diagnostic ECG Database\n","\n","- Number of Samples: 14552\n","- Number of Categories: 2\n","- Sampling Frequency: 125Hz\n","- Data Source: Physionet's PTB Diagnostic Database\n","- ECG lead II re-sampled to the sampling frequency of 125Hz as the input (from [ECG Heartbeat Classification: A Deep Transferable Representation](https://arxiv.org/pdf/1805.00794.pdf))\n","- Remark: All the samples are cropped, downsampled and padded with zeroes if necessary to the fixed dimension of 188.\n","- The final element of each row denotes the class to which that example belongs.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uhe6o8kccB5E"},"outputs":[],"source":["df_ptbd_normal = pd.read_csv(f\"{drive_path}/ecg_dataset/ptbdb_normal.csv\", header = None)\n","df_ptbd_abnormal = pd.read_csv(f\"{drive_path}/ecg_dataset/ptbdb_abnormal.csv\", header = None)\n","\n","# print shapes of the dataframes\n","print(\"The shape of the normal dataframe is : \", df_ptbd_normal.shape)\n","# print one example of the last column\n","print(\"Class : \", df_ptbd_normal.iloc[:, -1][0])\n","print(\"The shape of the abnormal dataframe is : \", df_ptbd_abnormal.shape)\n","# print one example of the last column\n","print(\"Class : \", df_ptbd_abnormal.iloc[:, -1][0])\n","\n","# classes are 0 (normal) and 1 (abnormal)\n","classes_names = {0 : \"normal\",\n","                 1 : \"abnormal\"}\n","\n","# get the number of columns in the dataframe\n","# the last column is the label/class\n","num_cols = df_ptbd_normal.shape[1] - 1\n","# the signal was resampled at frequency of 125Hz as the input\n","# compute the time vector\n","time = np.arange(0, num_cols) / 125\n","# convert to milliseconds\n","time = time * 1000\n","# print last time value\n","print(\"The last time value is : \", time[-1])\n","\n","# for the first \"num_cols\" and the time steps as column names\n","df_ptbd_normal.columns = list(time) + [\"label\"]\n","df_ptbd_abnormal.columns = list(time) + [\"label\"]\n","\n","# concatenate the two dataframes\n","df_ptbd = pd.concat([df_ptbd_normal, df_ptbd_abnormal], axis = 0)\n","\n","# count the number of samples in each class and plot a bar chart\n","# change the class names to \"normal\" and \"abnormal\"\n","# count the number of samples in each class\n","counts = df_ptbd[\"label\"].value_counts()\n","# substitute the class names: 0.0 -> normal, 1.0 -> abnormal\n","counts.index = counts.index.map(classes_names)\n","# create a figure\n","plt.figure(figsize = (10, 5))\n","# plot a bar chart\n","counts.plot(kind = \"bar\")\n","# plot xticks in angle\n","plt.xticks(rotation = 0)\n","plt.title(\"Number of samples in each class\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mH30YI52cB5E"},"outputs":[],"source":["# plot a a row of the dataframe\n","# select 10 random sequences with class 0 (normal) and 10 with class 1 (abnormal)\n","df_ptbd_normal = df_ptbd[df_ptbd[\"label\"] == 0].sample(10)\n","df_ptbd_abnormal = df_ptbd[df_ptbd[\"label\"] == 1].sample(10)\n","\n","# create a figure\n","plt.figure(figsize = (20, 10))\n","# plot againts the column names (time)\n","# plot the normal sequences\n","for i in range(df_ptbd_normal.shape[0]):\n","    if i == 0:\n","        plt.plot(df_ptbd_normal.columns[:-1], df_ptbd_normal.iloc[i, :-1], color = \"blue\", label = \"normal\")\n","    else:\n","        plt.plot(df_ptbd_normal.columns[:-1], df_ptbd_normal.iloc[i, :-1],color = \"blue\")\n","# plot the abnormal sequences\n","for i in range(df_ptbd_abnormal.shape[0]):\n","    if i == 0:\n","        plt.plot(df_ptbd_abnormal.columns[:-1], df_ptbd_abnormal.iloc[i, :-1], color = \"red\", label = \"abnormal\")\n","    else:\n","        plt.plot(df_ptbd_abnormal.columns[:-1], df_ptbd_abnormal.iloc[i, :-1], color = \"red\")\n","# create a legend for the plot, blue for normal and red for abnormal\n","plt.legend()\n","# set the title\n","plt.title(\"ECG sequences\")\n","# y lable is \"Normalized value\"\n","plt.ylabel(\"Normalized value\")\n","# x label is \"Time (ms)\"\n","plt.xlabel(\"Time (ms)\")\n","# show the plot\n","plt.show()\n","# close\n","plt.close()"]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from sklearn.model_selection import train_test_split"],"metadata":{"id":"I5GAApJ-ozMv"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["X = df_ptbd.iloc[:, :187].values\n","y = df_ptbd.iloc[:, 187].values\n","\n","X = X.reshape(-1, 187)  # Reshape X to (-1, 187)\n","y = y.reshape(-1, 1)    # Reshape y to (-1, 1)\n","\n","X_tensor = torch.tensor(X, dtype=torch.float32)\n","y_tensor = torch.tensor(y, dtype=torch.float32)"],"metadata":{"id":"B4S5LuHto7aM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Define the neural network model\n","class NeuralNet(nn.Module):\n","    def __init__(self, input_dim, hidden_dim, output_dim):\n","        super(NeuralNet, self).__init__()\n","\n","        # self.conv1 = nn.Conv1d(in_channels=32, out_channels=hidden_dim, kernel_size=3)\n","\n","        self.fc1 = nn.Linear(input_dim, 64)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(64, output_dim)\n","        self.sigmoid = nn.Sigmoid()\n","\n","    def forward(self, x):\n","        # out = self.conv1(x)\n","        out = self.fc1(x)\n","        out = self.relu(out)\n","        out = self.fc2(out)\n","        out = self.sigmoid(out)\n","        return out\n","\n","# Define the model parameters\n","input_dim = X.shape[1]\n","# hidden_dim = 64\n","output_dim = 1\n","\n","# Create an instance of the model\n","model = NeuralNet(input_dim, hidden_dim, output_dim)\n","\n","# Define the loss function and optimizer\n","criterion = nn.BCELoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.001)\n","\n","# Convert the data to PyTorch tensors\n","X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n","y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n","X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n","y_test_tensor = torch.tensor(y_test, dtype=torch.float32)"],"metadata":{"id":"OFmCbVnOpCjq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Train the model\n","num_epochs = 25\n","batch_size = 32"],"metadata":{"id":"O-zD5STyrD-o"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for epoch in range(1, num_epochs+1):\n","    # Mini-batch training\n","    for i in range(0, X_train_tensor.size(0), batch_size):\n","        batch_X = X_train_tensor[i:i+batch_size]\n","        batch_y = y_train_tensor[i:i+batch_size]\n","\n","        # Forward pass\n","        outputs = model(batch_X)\n","        loss = criterion(outputs, batch_y)\n","\n","        # Backward and optimize\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","    if(epoch%5==0):\n","      print(f\"Epoch {epoch}\")"],"metadata":{"id":"MVUEaKyWp8F4"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Evaluate the model\n","with torch.no_grad():\n","    outputs = model(X_test_tensor)\n","    predicted_labels = torch.round(outputs)\n","    accuracy = (predicted_labels == y_test_tensor).sum().item() / y_test_tensor.size(0)\n","    print(\"Test Accuracy:\", accuracy)"],"metadata":{"id":"sCFxcsXQp9JK"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from sklearn import metrics\n","confusion_matrix = metrics.confusion_matrix(y_test_tensor, predicted_labels)\n","cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = confusion_matrix)\n","\n","cm_display.plot()\n","plt.show()"],"metadata":{"id":"MEQUCNgrse9_"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.9"},"orig_nbformat":4,"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}